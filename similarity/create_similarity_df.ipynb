{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import Levenshtein as lev\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_train_data = pd.read_csv(\"../data/preprocessed/matched_train_data.csv\", low_memory=False, lineterminator='\\n')\n",
    "matched_train_data = matched_train_data.dropna(subset=[\"id_y\"]).reset_index()\n",
    "\n",
    "false_train_data = pd.read_csv(\"../data/preprocessed/false_train_data.csv\", low_memory=False, lineterminator='\\n')\n",
    "false_train_data = false_train_data.dropna(subset=[\"id_y\"]).reset_index()\n",
    "\n",
    "matched_test_data = pd.read_csv(\"../data/preprocessed/matched_test_data.csv\", low_memory=False, lineterminator='\\n')\n",
    "matched_test_data = matched_test_data.dropna(subset=[\"id_y\"]).reset_index()\n",
    "\n",
    "false_test_data = pd.read_csv(\"../data/preprocessed/false_test_data.csv\", low_memory=False, lineterminator='\\n')\n",
    "false_test_data = false_test_data.dropna(subset=[\"id_y\"]).reset_index()\n",
    "\n",
    "crossed_all_data = pd.read_csv(\"../data/preprocessed/crossed_all_data.csv\", low_memory=False, lineterminator='\\n')\n",
    "crossed_all_data = crossed_all_data.dropna(subset=[\"id_y\"]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_train_data = matched_train_data.fillna('')\n",
    "false_train_data = false_train_data.fillna('')\n",
    "matched_test_data = matched_test_data.fillna('')\n",
    "false_test_data = false_test_data.fillna('')\n",
    "crossed_all_data = crossed_all_data.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(62095, 19)\n(155285, 15)\n"
     ]
    }
   ],
   "source": [
    "print(matched_train_data.shape)\n",
    "print(false_train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(16864, 19)\n(38330, 15)\n"
     ]
    }
   ],
   "source": [
    "print(matched_test_data.shape)\n",
    "print(false_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_strings_similarity(google_strings, apple_strings):\n",
    "    similarities = []\n",
    "\n",
    "    for string_index in range(len(google_strings)):\n",
    "        google_string, apple_string = google_strings[string_index], apple_strings[string_index]\n",
    "        \n",
    "        if not isinstance(google_string, str) or not isinstance(apple_string, str):\n",
    "            similarities.append(0)\n",
    "            continue\n",
    "        \n",
    "        similarities.append(lev.ratio(google_string, apple_string))\n",
    "    \n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf_embeddings(documents):\n",
    "    vectorizer = TfidfVectorizer(lowercase=False)\n",
    "\n",
    "    return vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "def get_description_similarity(embeddings):\n",
    "    similarities = []\n",
    "\n",
    "    for embeddings_index in range(0, embeddings.shape[0], 2):\n",
    "        similarities.append(1 - spatial.distance.cosine(embeddings[embeddings_index].toarray().flatten(), embeddings[embeddings_index + 1].toarray().flatten()))\n",
    "    \n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matched_dataframe(data, label):\n",
    "    title_similarities = get_strings_similarity(data['title_x'], data['title_y'])\n",
    "    author_similarities = get_strings_similarity(data['author_x'], data['author_y'])\n",
    "    devsite_similarities = get_strings_similarity(data['devsite_x'], data['devsite_y'])\n",
    "\n",
    "    # combine the description one by one\n",
    "    x_y_descriptipns = [None]*(len(data['description_x'])+len(data['description_y']))\n",
    "    x_y_descriptipns[::2] = data['description_x']\n",
    "    x_y_descriptipns[1::2] = data['description_y']\n",
    "\n",
    "    embeddings = get_tfidf_embeddings(x_y_descriptipns)\n",
    "\n",
    "    description_similarities = get_description_similarity(embeddings)\n",
    "    labels = [label] * len(data)\n",
    "\n",
    "    data = list(zip(title_similarities, author_similarities, devsite_similarities, description_similarities, labels))\n",
    "    columns = ['title_similarity', 'author_similarity', 'devsite_similarity', 'description_similarity', 'label']\n",
    "\n",
    "    return pd.DataFrame(data=data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 44min 23s, sys: 39.9 s, total: 45min 3s\nWall time: 45min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "false_train_data_matched = get_matched_dataframe(false_train_data, label=0)\n",
    "train_data_matched = get_matched_dataframe(matched_train_data, label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(682455, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "X_train = pd.concat([false_train_data_matched, train_data_matched])\n",
    "X_train = X_train.sample(frac=1)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/scipy/spatial/distance.py:728: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "CPU times: user 3min 35s, sys: 14.4 s, total: 3min 50s\n",
      "Wall time: 3min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "false_test_data_matched = get_matched_dataframe(false_test_data, label=0)\n",
    "test_data_matched = get_matched_dataframe(matched_test_data, label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(170154, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "X_test = pd.concat([false_test_data_matched, test_data_matched])\n",
    "X_test = X_test.sample(frac=1)\n",
    "\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 12 µs, sys: 0 ns, total: 12 µs\nWall time: 15 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def get_predictions(X, X_t, labels_to_drop):\n",
    "    model = XGBClassifier()\n",
    "    model.fit(X.drop(columns=labels_to_drop), X[\"label\"])\n",
    "    \n",
    "    y_pred = model.predict(X_t.drop(columns=labels_to_drop))\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[16:52:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.998719267102962"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "soft_pred = get_predictions(X_train, X_test, [\"label\"])\n",
    "average_precision = balanced_accuracy_score(X_test['label'], soft_pred)\n",
    "average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hard_data(data):\n",
    "    data_sum = data.copy()\n",
    "    data_sum['sum'] = data_sum.drop(columns=[\"label\"]).sum(axis=1)\n",
    "    data_sum_top_25 = data_sum.nlargest(int(data.shape[0] * 0.25), 'sum')\n",
    "    print(data_sum_top_25[\"sum\"].mean(), data.drop(columns=[\"label\"]).sum(axis=1).mean())\n",
    "    return data_sum_top_25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'false_train_data_matched' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3a72bb244666>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfalse_train_data_matched_hard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_hard_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfalse_train_data_matched\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfalse_test_data_matched_hard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_hard_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfalse_test_data_matched\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'false_train_data_matched' is not defined"
     ]
    }
   ],
   "source": [
    "false_train_data_matched_hard = get_hard_data(false_train_data_matched)\n",
    "false_test_data_matched_hard = get_hard_data(false_test_data_matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_df(first, second):\n",
    "    conc = pd.concat([first, second])\n",
    "    conc = conc.sample(frac=1)\n",
    "\n",
    "    return conc.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_hard = concat_df(false_train_data_matched_hard, train_data_matched)\n",
    "X_test_hard = concat_df(false_test_data_matched_hard, test_data_matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'X_train_hard' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-39a1fa01f24d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_hard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train_hard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sum\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_hard' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_hard[X_train_hard[\"label\"] == 0].sort_values(by=[\"sum\"], ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(217140, 6)\n(55104, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_hard.shape)\n",
    "print(X_test_hard.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[16:54:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9982792410273427"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "hard_pred = get_predictions(X_train_hard, X_test_hard, [\"label\", \"sum\"])\n",
    "average_precision = balanced_accuracy_score(X_test_hard[\"label\"], hard_pred)\n",
    "average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LABELS --> ['label']\n",
      "LABELS --> ['title_similarity', 'label']\n",
      "[18:06:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "SCORE --> 0.9762907120275155\n",
      "LABELS --> ['author_similarity', 'label']\n",
      "[18:06:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "SCORE --> 0.8650000871573762\n",
      "LABELS --> ['devsite_similarity', 'label']\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[18:06:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "SCORE --> 0.8883062201262257\n",
      "LABELS --> ['description_similarity', 'label']\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[18:06:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "SCORE --> 0.9860792110358669\n",
      "LABELS --> ['title_similarity', 'author_similarity', 'label']\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[18:07:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "SCORE --> 0.9888927639767358\n",
      "LABELS --> ['title_similarity', 'devsite_similarity', 'label']\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[18:07:26] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "SCORE --> 0.9914831485104104\n",
      "LABELS --> ['title_similarity', 'description_similarity', 'label']\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[18:07:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "SCORE --> 0.9984298925520754\n",
      "LABELS --> ['author_similarity', 'devsite_similarity', 'label']\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[18:07:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "SCORE --> 0.9533695870405697\n",
      "LABELS --> ['author_similarity', 'description_similarity', 'label']\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[18:08:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "SCORE --> 0.9952446698206223\n",
      "LABELS --> ['devsite_similarity', 'description_similarity', 'label']\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[18:08:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "SCORE --> 0.9941013424726143\n",
      "LABELS --> ['title_similarity', 'author_similarity', 'devsite_similarity', 'label']\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[18:08:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "SCORE --> 0.9938347840886117\n",
      "LABELS --> ['title_similarity', 'author_similarity', 'description_similarity', 'label']\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[18:09:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "SCORE --> 0.9987099972934521\n",
      "LABELS --> ['title_similarity', 'devsite_similarity', 'description_similarity', 'label']\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[18:09:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "SCORE --> 0.9980436593086646\n",
      "LABELS --> ['author_similarity', 'devsite_similarity', 'description_similarity', 'label']\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[18:09:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "SCORE --> 0.9966593406482236\n",
      "LABELS --> ['title_similarity', 'author_similarity', 'devsite_similarity', 'description_similarity', 'label']\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[18:10:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "SCORE --> 0.998719267102962\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain, combinations\n",
    "\n",
    "features = [\"title_similarity\", \"author_similarity\", \"devsite_similarity\", \"description_similarity\"]\n",
    "\n",
    "def powerset(iterable):\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
    "\n",
    "all_features_combinations = list(powerset(features))\n",
    "\n",
    "for combination in all_features_combinations:\n",
    "    l = list(combination)\n",
    "    l.append(\"label\")\n",
    "    print(f'LABELS --> {l}')\n",
    "    if(len(l) > 1):\n",
    "        soft_pred = get_predictions(X_train[l], X_test[l], [\"label\"])\n",
    "        average_precision = balanced_accuracy_score(X_test['label'], soft_pred)\n",
    "        print(f'SCORE --> {average_precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        title_similarity  label\n",
       "549603          0.250000      0\n",
       "22648           0.307692      0\n",
       "539416          0.250000      0\n",
       "287748          0.181818      0\n",
       "492207          0.000000      0\n",
       "...                  ...    ...\n",
       "438828          0.250000      0\n",
       "495538          0.181818      0\n",
       "133185          0.285714      0\n",
       "405502          0.000000      0\n",
       "151954          0.000000      0\n",
       "\n",
       "[682455 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title_similarity</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>549603</th>\n      <td>0.250000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>22648</th>\n      <td>0.307692</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>539416</th>\n      <td>0.250000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>287748</th>\n      <td>0.181818</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>492207</th>\n      <td>0.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>438828</th>\n      <td>0.250000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>495538</th>\n      <td>0.181818</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>133185</th>\n      <td>0.285714</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>405502</th>\n      <td>0.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>151954</th>\n      <td>0.000000</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>682455 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "X_train[[\"title_similarity\", \"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/scipy/spatial/distance.py:728: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "CPU times: user 13min 27s, sys: 17.8 s, total: 13min 45s\n",
      "Wall time: 14min\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "false_train_data_matched = get_matched_dataframe(false_train_data, label=0)\n",
    "train_data_matched = get_matched_dataframe(matched_train_data, label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'false_train_data' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-47885159af71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfalse_train_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfalse_train_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'false_train_data' is not defined"
     ]
    }
   ],
   "source": [
    "false_train_data[\"label\"] = 0\n",
    "false_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(217380, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "X_train = pd.concat([false_train_data_matched, train_data_matched])\n",
    "X_train = X_train.sample(frac=1)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 1min 6s, sys: 5.52 s, total: 1min 12s\nWall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "false_test_data_matched = get_matched_dataframe(false_test_data, label=0)\n",
    "test_data_matched = get_matched_dataframe(matched_test_data, label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(55194, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "X_test = pd.concat([false_test_data_matched, test_data_matched])\n",
    "X_test = X_test.sample(frac=1)\n",
    "\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "title_similarity          0.222222\n",
       "author_similarity         0.333333\n",
       "devsite_similarity        0.000000\n",
       "description_similarity    0.076723\n",
       "label                     0.000000\n",
       "Name: 4702, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "X_test.iloc[1401]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[12:06:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train.drop(columns=[\"label\"]), X_train[\"label\"])\n",
    "    \n",
    "y_pred = model.predict(X_test.drop(columns=[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 0,  4,  5,  9, 15, 26, 29, 30, 33, 35, 36, 42, 45, 48, 50, 55, 61,\n",
       "       62, 65, 73])"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "np.where(y_pred == 1)[0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'matched_test_data' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-75cb2d0764c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatched_test_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m45\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'matched_test_data' is not defined"
     ]
    }
   ],
   "source": [
    "match = matched_test_data.iloc[45]\n",
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "crossed_all_data_matched = get_matched_dataframe(crossed_all_data, label=0)\n",
    "crossed_all_data_matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_pred_crossed = model.predict(crossed_all_data_matched.drop(columns=[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(611,)"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "np.where(y_pred_crossed == 1)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-70e2559f0a69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_crossed\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "np.where(y_pred_crossed == 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        title_similarity  author_similarity  devsite_similarity  \\\n",
       "422583               1.0                0.5            0.181818   \n",
       "\n",
       "        description_similarity  label  \n",
       "422583                0.091055      0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title_similarity</th>\n      <th>author_similarity</th>\n      <th>devsite_similarity</th>\n      <th>description_similarity</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>422583</th>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>0.181818</td>\n      <td>0.091055</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "# 422583\n",
    "# 883787\n",
    "# 894341\n",
    "\n",
    "# Check the score for each match\n",
    "# Short string match should get low score\n",
    "# Check the devsite histogram\n",
    "crossed_all_data_matched[crossed_all_data_matched.index == 883787]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         index                    id_x  store_x apple_maincategory_x  \\\n",
       "422583  422583  howto.become.famous.se        0                        \n",
       "\n",
       "       google_maincategory_x title_x  author_x         devsite_x  \\\n",
       "422583             Lifestyle     how  solution  easyloveyourself   \n",
       "\n",
       "                                            description_x        id_y  \\\n",
       "422583  how to become famous  a quick guide at one tim...  1111808667   \n",
       "\n",
       "        store_y  apple_maincategory_y google_maincategory_y title_y author_y  \\\n",
       "422583        1                  6017                           how     toan   \n",
       "\n",
       "       devsite_y                                      description_y  \n",
       "422583    fewfew  wanna draw your favorite characters the easy w...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>id_x</th>\n      <th>store_x</th>\n      <th>apple_maincategory_x</th>\n      <th>google_maincategory_x</th>\n      <th>title_x</th>\n      <th>author_x</th>\n      <th>devsite_x</th>\n      <th>description_x</th>\n      <th>id_y</th>\n      <th>store_y</th>\n      <th>apple_maincategory_y</th>\n      <th>google_maincategory_y</th>\n      <th>title_y</th>\n      <th>author_y</th>\n      <th>devsite_y</th>\n      <th>description_y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>422583</th>\n      <td>422583</td>\n      <td>howto.become.famous.se</td>\n      <td>0</td>\n      <td></td>\n      <td>Lifestyle</td>\n      <td>how</td>\n      <td>solution</td>\n      <td>easyloveyourself</td>\n      <td>how to become famous  a quick guide at one tim...</td>\n      <td>1111808667</td>\n      <td>1</td>\n      <td>6017</td>\n      <td></td>\n      <td>how</td>\n      <td>toan</td>\n      <td>fewfew</td>\n      <td>wanna draw your favorite characters the easy w...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "xasd = crossed_all_data[crossed_all_data.index == 883787]\n",
    "xasd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "crossed_all_data_matched['description_similarity'] = crossed_all_data_matched['description_similarity'].fillna(0)\n",
    "crossed_all_data_matched['description_similarity'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.02313763 0.0168818 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "pca = PCA(2)\n",
    "X = crossed_all_data_matched.drop(columns=[\"label\"])\n",
    "X_transformed = pca.fit_transform(X)\n",
    "eigenvalues = pca.explained_variance_\n",
    "print(eigenvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'X_transformed' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-47e5e90e8693>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_transformed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_transformed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_transformed' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X_transformed[:,0],X_transformed[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.44893883 0.03946634]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "pca = PCA(2)\n",
    "X = X_train.drop(columns=[\"label\"])\n",
    "X_transformed = pca.fit_transform(X)\n",
    "eigenvalues = pca.explained_variance_\n",
    "print(eigenvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'X_transformed' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e9e9edb862e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_transformed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_transformed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_transformed' is not defined"
     ]
    }
   ],
   "source": [
    "plt.scatter(X_transformed[:,0],X_transformed[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}